{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext, Row\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark import SparkContext\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp import Finisher\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-FD0BJOT.fritz.box:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PythonNLPAPPLIER</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f8502a7940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "   .appName(\"PythonNLPAPPLIER\")\\\n",
    "   .getOrCreate()\n",
    "\n",
    "# sqlContext = SQLContext(spark)\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"nlp converter\")\\\n",
    "#     .master(\"local[*]\")\\\n",
    "#     .config(\"spark.driver.memory\",\"16G\")\\\n",
    "#     .config(\"spark.driver.maxResultSize\", \"300\") \\\n",
    "#     .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "#     .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.6\")\\\n",
    "#     .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43885"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = r\"files\\raw_texts.feather\"\n",
    "# pandas_df =  pd.read_feather(source+path).drop_duplicates(subset = 'URL', keep = 'first').reset_index(drop=True)\n",
    "# pandas_df = pandas_df[pandas_df['URL_TEXT']!=\"\"]\n",
    "# spark_df = sqlContext.createDataFrame(pandas_df)\n",
    "\n",
    "source = os.path.dirname(os.path.realpath('__file__')).split(\"src\")[0]\n",
    "path = r\"files\\raw_texts.parquet\"\n",
    "spark_df = spark.read.parquet(source+path).where(f.col(\"URL_TEXT\")!= \"\")\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = [\"(?:<from.*?>)(.*?)(?:<\\\\/from>)\"]\n",
    "html = [\"<(?:\\\"[^\\\"]*\\\"['\\\"]*|'[^']*'['\\\"]*|[^'\\\">])+>\"]        \n",
    "random_pattern = ['^@.*\\{.*\\}', '^\\..*\\{.*\\}','\\s\\s+','\\xa0','dbx707', '\\xe2','\\x80',\"\\x8b\", r\"\\{\\{\\.*\\}\\}\", \"\\x9d\", \"\\u200b\"]# only digits: r'\\b[0-9]+\\b\\s*'\n",
    "url = [\"^https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[äöüßa-zA-Z0-9()]{1,6}\\\\b(?:[-a-zäöüßA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\", \"www\\w*de\",\"www\\w*com\"]\n",
    "email = [\"^\\S+@\\S+\\.\\S+$\"]\n",
    "zip = [\"^[0-9]{5}(?:-[0-9]{4})?\\s?\\w*$\"]\n",
    "phone = [\"^\\\\+?[1-9][0-9]{7,14}$\"]\n",
    "dates = [\"^[0-9]{1,2}\\\\/[0-9]{1,2}\\\\/[0-9]{4}$\",\"^[0-9]{1,2}\\\\-[0-9]{1,2}\\\\-[0-9]{4}$\", \"^[0-9]{4}\\\\-[0-9]{1,2}\\\\-[0-9]{1,2}$\"]\n",
    "website_stopwords = [\"explore\",\"allgemeine geschäftsbedingungen\",\"allgemein\\*\",'richtlinie\\w*',\"\\w*recht\\w* hinweis\\w*\",\"\\w*recht\\w*\",\"\\w*datenschutz\\w*\", \"privacy\",\"policy\\w*\",\"cooky\\w*\",\"cookie\\w*\",\"content\\w*\",\" to \",\\\n",
    "        \"anmeld\\w*\",  \"abmeld\\w*\", \"login\",\"log in\",\"logout\", \"log out\", \"kunden login\", \"online\",\"zurück\",\"back\",\"start\",\"select\\w*\", \"ausw\\w*\",\"close\",\\\n",
    "            \"extras\",\"news\",\"report\\w*\",\"impressum\",\"newsletter\\w*\", \"owner\",\"internet\", \"website\\w*\", \"email\\w*\", \"e-mail\\w*\", \"mail\\w*\", \"isbn\", \"issn\",\\\n",
    "                \"produkte\", \"partner\",\"übersicht\", \"veranstaltungen\", \"suche\\w*\",\"kauf\\w*\", \"angebot\\w*\", \"konfigur\\w*\", \"configur\\w*\",\"nutzer\\w*\",\"icon\\w*\",\\\n",
    "                    \"zubehör\", \"garantie\", \"mehr\", \"modell\\w*\", \"kontakt\\w*\",\"contact\\w*\",\"anfrage\\w*\",\"skip\",'useful links','link\\w*',\"pin\\w*\",\"passw\\w*\", \"password\\w*\",\\\n",
    "                        \"buchen\",\"book\" \"anfahrt\", \"finanzdienstleistung\\w*\" \"connected\", \"required\", \"sitemap\\w*\", \"\\w*\\s?abo\\w*\", 'social media', \"socialmedia\",\\\n",
    "                            \"englisch\", \"english\",\"deutsch\",\"german\",\"google\", \"wikipedia\", \"navigation\",\"\\w*shop\\w*\", \"\\w*magazin\\w*\", \"lifestyle\",\\\n",
    "                                \"facebook\\w*\", \"youtube\\w*\",\"instagram\\w*\",\"xing\\w*\",\"linkedin\\w*\", \"blog\\w*\",\"spiegel\\w*\",\"twitter\\w*\",\"sms\",\"video\"\\\n",
    "                                    \"archiv\\w*\", \"artikel\\w*\", \"article\\w*\",\"side\\w*\", \"seite\\w*\",\"site\",\"app\\w*\",\"\\s?abgerufen\\s?\\w*\\s*\\d*\",\\\n",
    "                                        \"januar\", \"februar\", \"märz\", \"april\", \"mai\", \"juni\", \"juli\", \"august\", \"september\", \"oktober\", \"november\", \"dezember\",\\\n",
    "                                            \"dbx707\", \"db11\",\"\\w*\\s?straße\\s?\\d*\",\"\\w*\\s?strasse\\w*\", \"tel\\w*\", \"\\w*\\s?download\\w*\",\\\n",
    "                                                \"covid\\w*\\s?\\d*\", \"corona\\w*\\s?\\d*\"]\n",
    "                                \n",
    "domain_stopwords = [\"(g/km)\",\"use case\\w*\", \"unternehme\\w*\", \"gmbh\", \"cokg\", \"co kg\", \"consult\\w*\", \"handel\\w*\", \"händler\\w*\", \"leistung\\w*\"]\n",
    "numbers_only = [\"^\\\\d+$\",\"^\\s?[0-9]+(\\s+[0-9]+)*\\s?$\", \"\\(.*\\)\",\"\\[.*\\]\", \"^\\d+.\\d+\",\" \\\\d+ \"]\n",
    "special_characters = ['[^äöüßA-Za-z0-9 ]+']#['[\\(,.:\\);^]']\n",
    "short_words = ['^\\.{0,3}$']\n",
    "\n",
    "all_pattern_to_remove = email+xml+html+random_pattern+url+zip+phone+dates+website_stopwords+domain_stopwords+numbers_only+special_characters+short_words\n",
    "spark_df = spark_df.withColumnRenamed(\"URL_TEXT\", 'text')\n",
    "spark_df = spark_df.withColumn('text', f.lower(f.col('text')))\n",
    "spark_df = spark_df.withColumn('text', f.regexp_replace(f.col('text'), '\\r+|\\n+|\\t+/', ''))\n",
    "spark_df = spark_df.withColumn('text', f.regexp_replace(f.col('text'),'[\\|]+', ' '))\n",
    "spark_df = spark_df.withColumn('text', f.regexp_replace(f.col('text'),'\\s\\s+', ' '))\n",
    "for pattern in all_pattern_to_remove:\n",
    "    spark_df = spark_df.withColumn(\"text\", f.regexp_replace(f.col('text'), pattern, \"\"))\n",
    "spark_df = spark_df.withColumn('text', f.regexp_replace(f.col('text'),'\\s\\s+', ' ')) \n",
    "\n",
    "# regexTokenizer = RegexTokenizer(pattern='\\w+', inputCol=\"text\", outputCol=\"words\")\n",
    "# spark_df = regexTokenizer.transform(spark_df)\n",
    "spark_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "language_detector = LanguageDetectorDL.pretrained(\"ld_wiki_tatoeba_cnn_21\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"lang\")\\\n",
    "    .setThreshold(0.8)\\\n",
    "    .setCoalesceSentences(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"Sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setIncludeMetadata(True)\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    ".setStages([\n",
    "    documentAssembler,\n",
    "    language_detector,\n",
    "    sentenceDetector,\n",
    "    regexTokenizer,\n",
    "    finisher\n",
    "    ])\n",
    "\n",
    "result = pipeline.fit(spark_df).transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29e3f5a20b6bf6aef5494d745dbb8622970e33bcbdb37d238be21287c6d6aad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
